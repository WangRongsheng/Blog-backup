# Research title

Image Registration on breast ultrasound images

# Introduction

# Problem statement

Breast cancer has become one of the biggest killers affecting womenâ€™s health.Screening and early treatment with early 3D breast ultrasound images.In a breast image, there are many slices that contain the entire thymus scan. These images are usually 2D, and 2D images show a lot of information, but 3D is considered to be a more effective way to show it. This requires the use of medical image registration. Using medical image registration to do image registration on breast ultrasound images to assist doctors in early disease screening and treatment guidance to provide observation indicators.However, there are few existing studies with high-quality datasets and papers for efficient image registration of breast ultrasound images. Combining real breast ultrasound images provided by hospitals and previous studies, we hope to construct a high-quality dataset for breast ultrasound alignment studies, and also explore image registration work on breast images based on this dataset, which can eventually effectively help breast clinicians to reduce disease diagnosis time and provide health protection for patients.

# Background

Thanks to the rapid development of biomedical technology, many medical screening images are also more diverse and useful, such as DICOM, CT, etc.These images are used by doctors to screen for disease and assist in treatment.With the development of deep learning, the classification and segmentation of medical images has also become more common and useful. It is often called computer-aided diagnosis and treatment.At present, the assisted diagnosis and treatment using deep learning methods has reached or exceeded the level of doctors in terms of accuracy and speed. This also greatly alleviates the suffering of lack of medical resources and early disease screening.

AI-based image classification and image segmentation on medical image information has been a great success. There is still a great potential for image registration on medical.Image registration is an important technique in image processing and a prerequisite for image fusion. Image registration is an image processing process that aligns two or more images of the same scene taken by the same sensor at different times, from different viewpoints or using different sensors in spatial locations. The key to image registration is to find the spatial transformation relationship between two or more images to be aligned, so that the corresponding points on the images to be aligned are in the same coordinate system.

Exploring unsupervised learning or weakly supervised learning for aligning breast ultrasound images.Ultimately, it can effectively help breast clinicians shorten disease diagnosis time and provide health protection for patients.

# Related work

Before the rise of deep learning techniques, there were already many traditional registration methods, but the emergence of deep learning has greatly influenced the hotspots of image registration research [1]. Since the success of AlexNet in the 2012 ImageNet challenge, deep learning has enabled state-of-the-art performance for many computer vision tasks, such as target detection, feature extraction, segmentation, image classification, image denoising, and image reconstruction. Initially, deep learning techniques were mainly used for augmented iterative, intensity-based medical image registration, but the registration speed was slow and the need for fast registration algorithms drove the development of supervised registration methods based on end-to-end deep learning. The difficulty of obtaining real deformation fields by supervised learning has motivated many scholars to develop unsupervised registration frameworks for end-to-end use. Currently, the biggest challenge in unsupervised registration frameworks is image similarity quantification, and recent research on information-theoretic-based similarity metrics, weakly supervised frameworks, and generative adversarial networks (GAN) frameworks are all strategies used to address image similarity quantification.

The supervised registration method requires the real deformation field as the gold standard, and the real deformation field is more difficult to obtain. The proposed weakly supervised method alleviates the dependence on the gold standard. Weak supervision utilizes the segmental overlap of the corresponding anatomical structures to design the loss function, i.e., the similarity metric of the labels is used as the objective function to iteratively update the weights of the network in reverse. The registration results of weakly supervised learning, which have relatively few results compared to the previous two methods, mostly use similarity measure-based and non-rigid registration. instead of using artificially generated deformation fields, Hu et al [4] used label similarity to train the network for 3D MRI and ultrasound image registration. Similarly, Hering et al [5] combined the complementary information of segmentation labels and image similarity to train the network. The experimental results show that the Dice score of this method is higher than using only image similarity loss and segmentation label loss. Unlike the above methods, Liu et al [6] used representation learning to learn feature descriptors with confidence level probability maps and trained the network using a supervised synthetic transform and unsupervised descriptors combined with image similarity loss.

Despite the great results of supervised and weakly supervised learning for image registration, the difficulty of obtaining labels and the difficulty of defining appropriate loss functions without labels has motivated many scholars to explore unsupervised learning methods.In 2015, Jaderberg et al [7] proposed a spatial transformer networks (STN), which can perform spatial transformer networks on the network within the data for spatial manipulation. Because STNs can calculate the similarity loss of images during training, it makes unsupervised learning image registration techniques possible. A typical deformation unsupervised transform estimation network specifically takes an image pair as input and directly outputs a predicted random displacement vector field (DVF). the STN uses this network to warp a moving image to generate a warped image; it then computes the similarity loss of the warped image to the fixed image, and the DVF smoothness constraint is usually used to regularize the predicted DVF for regularization. The following classification describes the literature emerging in this area. Through the research, it is found that unsupervised learning registration methods are mostly used for non-rigid registration. Unsupervised image registration methods based on image similarity do not require labels, however, quantification of image similarity remains a challenge in multimodal registration applications. Therefore, unsupervised learning based on image similarity for registration is mostly used for single-mode registration. Given that multimodal registration is often required in many clinical applications, researchers have started to investigate unsupervised learning to learn feature representations to determine the best spatial registration, with some results.

The most widely used unsupervised medical image alignment model is VoxelMorph [8]. VoxelMorph-based thoracic CT image alignment [9] and brain CT alignment [10]

# Proposed approach

## Data Collection

We have obtained consent for cooperation from Xijing Hospital. Xijing Hospital will provide female breast ultrasound image data for our study, which will include not only raw patient data, but also annotation of the data. Using these high quality datasets, we can perform fundamental analysis of the data, summarize the age distribution of the affected individuals, etc.

## Traditional Image Registration

Based on the real breast ultrasound image data, we use the existing methods: non-rigid alignment and rigid alignment to perform the alignment of breast images, and explore the alignment effect of breast images under the traditional way of alignment. This method can also be used as a baseline for future research.

## AI-based Image Registration

The calculation amount of image registration based on traditional methods is huge, and parameters cannot be shared for different registration images.Currently, supervised learning and unsupervised learning in deep learning have greatly improved in medical image registration. The advantages of deep learning-based image registration are fast computation and parameters can be shared between different registered images. However, compared to supervised learning, unsupervised learning does not require huge standard work and larger computation, and is very suitable for image registration.What's more, it's worth mentioning that studies have found that other semantic information is rarely fused in current registration tasks, and better performance can be achieved by incorporating more semantic information.We expect to apply the project to the ground, rather than stop at research.

## Clinical validation

Our work will not only be in the paper, but also in the early stage to see if our method is effective by comparing doctors with model-aligned breast images, and then by conducting clinical trials in collaboration with Xijing Hospital, and then we hope to benefit the human society with our research results.

# Reference

[1] HILL D L G, BATCHELOR P G, HOLDEN M, et al. Medical image registration[J]. Physics in Medicine & Biology, 2001, 46(3): R1-R45.
[4] HU Y P, MODAT M, GIBSON E, et al. Label-driven weakly-supervised learning for multimodal deformable image registration[C]//2018 IEEE 15th International Symposium on Biomedical Imaging. Washington DC, USA: IEEE, 2018.
[5] HERING A, KUCKERTZ S, HELDMANN S, et al. Enhancing label-driven deep deformable image registration with local distance metrics for state-of-the-art cardiac motion tracking[M]//HANDELS H, DESERNO T M, MAIER A, et al. Bildverarbeitung fÃ¼r die Medizin 2019. Wiesbaden: Springer, 2019, doi: 10.1007/978-3-658-25326-4_69.
[6] LIU C, MA L H, LU Z M, et al. Multimodal medical image registration via common representations learning and differentiable geometric constraints[J]. Electronics Letters, 2019, 55(6): 316-318. DOI:10.1049/el.2018.6713
[7] JADERBERG M, SIMONYAN K, ZISSERMAN A, et al. Spatial transformer networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems. Montreal, Quebec, Canada: NIPS, 2015: 2017â€“2025.
[8] Balakrishnan G, Zhao A, Sabuncu M R, et al. VoxelMorph: a learning framework for deformable medical image registration[J]. IEEE transactions on medical imaging, 2019, 38(8): 1788-1800.
[9] Zheng Y, Jiang S, Yang Z. Deformable registration of chest CT images using a 3D convolutional neural network based on unsupervised learning. J Appl Clin Med Phys. 2021 Oct;22(10):22-35. doi: 10.1002/acm2.13392. Epub 2021 Sep 10. PMID: 34505341; PMCID: PMC8504612.
[10] Yuan H, Yang M, Qian S, Wang W, Jia X, Huang F. Brain CT registration using hybrid supervised convolutional neural network. Biomed Eng Online. 2021 Dec 29;20(1):131. doi: 10.1186/s12938-021-00971-8. PMID: 34965854; PMCID: PMC8715595.
