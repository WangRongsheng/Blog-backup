---
title: 浅谈数据降维
date: 2019-11-30 11:15:50
thumbnail: https://i.loli.net/2019/11/30/YcZ6bDpCBa4dJNu.png
tags: 降维
categories: AI
---

数据降维算法是机器学习算法中的大家族，与分类、回归、聚类等算法不同，它的目标是将向量投影到低维空间，以达到某种目的如可视化，或是做分类。

<!--more-->

# 为什么要进行降维？

所谓降维，即用一组个数为 d 的向量 Zi 来代表个数为 D 的向量 Xi 所包含的有用信息，其中 d<D，通俗来讲，即将高维度下降至低维度；将高维数据下降为低维数据。

通常，我们会发现大部分数据集的维度都会高达成百乃至上千，而经典的 **MNIST数据集** ，其维度都是 64。

但在实际应用中，我们所用到的有用信息却并不需要那么高的维度，而且每增加一维所需的样本个数呈指数级增长，这可能会直接带来极大的**「维数灾难」** ;而数据降维就可以实现：

- 使得数据集更易使用

- 确保变量之间彼此独立

- 降低算法计算运算成本

去除噪音一旦我们能够正确处理这些信息，正确有效地进行降维，这将大大有助于减少计算量，进而提高机器运作效率。而数据降维，也常应用于文本处理、人脸识别、图片识别、自然语言处理等领域。

# 数据降维原理

往往高维空间的数据会出现分布稀疏的情况，所以在降维处理的过程中，我们通常会做一些数据删减，这些数据包括了冗余的数据、无效信息、重复表达内容等。

例如：现有一张 1024\*1024 的图，除去中心 50\*50 的区域其它位置均为零值，这些为零的信息就可以归为无用信息;而对于对称图形而言，对称部分的信息则可以归为重复信息。

因此，大部分经典降维技术也是基于这一内容而展开，其中降维方法又分为线性和非线性降维，非线性降维又分为基于核函数和基于特征值的方法。

## 1.线性降维方法

- PCA 、ICA LDA、LFA、LPP(LE的线性表示)

## 2.非线性降维方法

- 基于核函数的非线性降维方法——KPCA 、KICA、KDA

- 基于特征值的非线性降维方法(流型学习)——ISOMAP、LLE、LE、LPP、LTSA、MVU

在我的Github中我已经搜集整理了 PCA、KPCA、LDA、MDS、ISOMAP、LLE、TSNE、AutoEncoder、FastICA、SVD、LE、LPP 共 12 种经典的降维算法，并提供了相关资料、代码以及展示。

