本次我们学习与机器学习相关的统计学相关知识，主要包括统计量、中心极限定理、均值假设检验、AB 实验方法等内容。

<center><img src="https://s1.ax1x.com/2020/04/21/J8vPnf.png" alt="J8vPnf.png" border="0" /></center>

根据现状，很多从事机器学习工作相关的人并没有太多统计学的知识储备。不得不说，缺乏统计学的知识，并不会阻碍你用机器学习技术去建立模型。那么为什么还要在此强调统计学的重要性呢？甚至还专门用一个课时来说明它呢？原因主要在于模型灰度或应用阶段的评估。我们知道，机器学习是以数据分析、预测为基础，来优化业务决策的一门技术。那么，在模型灰度测试时，如果你不具备基础的统计学知识，就无法分辨模型带来的效果提升是随机波动还是真实收益。因此这一课时，我们就来铺垫与机器学习相关的基础统计学知识。

# 统计量

<center><img src="https://s1.ax1x.com/2020/04/21/J8xkKx.png" alt="J8xkKx.png" border="0" /></center>

统计量是指用来描述一大堆数字性质的数值，例如均值、中位数、方差、标准差，等等。假设从1~9这9个数字中进行抽样，得到如图所示的结果，其中每个绿色的点代表一个采样样本。若想描述清楚这些样本的数值性质，肯定是不能把每个样本都说一遍的，那么就需要借助统计量来进行描述了。

首先是均值，就是所有采样值的平均值。公式为：

<center><img src="https://s1.ax1x.com/2020/04/21/J8xBMq.png" alt="103" border="0"></center>

接着是中位数，它是按顺序排列的一组数据中居于最中间位置的数。

方差是衡量一组数据离散程度的度量。计算方法是每个样本值与均值之差平方的均值。公式为

<center><img src="https://s1.ax1x.com/2020/04/21/J8xwzn.png" alt="104" border="0"></center>

最后，标准差5。它和方差非常相似，只需要对方差开平方即可，就不再熬述其公式了。

这些统计量中最重要的要算均值和标准差了，会在后续频繁使用。有了这些统计量，我们就可以来描述样本的数值大小情况、样本与均值的离散程度等统计上的数值信息了。

## 例题

<center><img src="https://s1.ax1x.com/2020/04/21/J8zJ61.png" alt="J8zJ61.png" border="0" /></center>

假设有个小团队的leader，他有9个员工。现在这个leader想以双倍的加班工资，让员工周六也来公司加班。但是他不确定员工对这个决策是否支持。因此，他决定调研所有的9名员工对这个政策的支持度。在回收到了表中的9份调研结果后，问题出现了。他如何从9份回答中，提取出具有代表性的结果并作出决策呢？

<center><img src="https://s1.ax1x.com/2020/04/21/J8zs1A.png" alt="J8zs1A.png" border="0" /></center>

这时，统计量的作用就发挥了价值。首先计算均值，9个数值求平均数，结果为3.4。接着看一下中位数。把这9个数字按照大小顺序排列，找到中间第5大的数字，得到中位数是4。再接着，计算方差。根据公式计算得到方差为2.7。开个根号，就得到了标准差1.6。经过这些统计量的分析就能得到下面的结论。首先，均值3.4分、中位数4分都大于了代表无所谓的3分，说明更多的员工是支持这项决策的。然而，方差和标准差都比较大，反映出员工的支持度波动比较大。也就是说存在部分员工特别支持这个决策，同时部分员工特别抵触这个决策。因此，决策的落地执行风险比较大。

通过这个例子我们会发现，在面对大量数据时，你仅仅通过一些统计量信息，就能把大量数据背后隐藏的性质、规律描述清楚，并形成某些结论，辅助你作出更客观、稳健的决策。

# 中心极限定理

从前面的例子可以发现，只要计算出某个分布的统计量，就能解决统计学面临的绝大多数问题。然而挑战在于，在很多场景下，你根本拿不到全部的样本数据。前面的例子比较简单，这个leader只有9个员工，全部调研一遍是完全可行的。但换个问题，情况可能完全不一样。例如，调研全国男女人口比例是多少。难道我们要把全国13亿人都问一遍吗？显然不可能。这个时候，就需要对13亿人进行采样，得到采样集合。接着可以计算采样集合中的统计量。那么问题来了，有了采样、有了采样集合的统计量，如何对总体的统计量进行估计呢？此时，就需要统计学中的圣经级定理——中心极限定理了。

<center><img src="https://s1.ax1x.com/2020/04/21/JGSAAO.png" alt="JGSAAO.png" border="0" /></center>

极限定理能解决的问题很明确，即对于一个未知的总体，如何通过某些手段计算出总体的统计量。

中心极限定理的内容为，假设从均值为μ，方差为σ2的任意一个总体中，抽取样本量为n的样本。当n充分大时，样本均值 $\bar{x}$ 的分布近似服从均值为、方差为σ2/n的正态分布。其在统计学中，通常认为n>=30即为大样本。

中心极限定理有几个要素：

- 它不需要总体满足什么分布的条件，哪怕不是正态分布的任意某个分布都适用。
- 它要求采样n至少为30。

中心极限定理的价值在于，它从统计量上，构建了总体和抽样之间的联系。别忘了，我们的现实世界中，上帝视角只是理论存在，因此由“抽样估计总体”必然是永恒的模式。

## 例题

<center><img src="https://s1.ax1x.com/2020/04/21/JG9rp4.png" alt="JG9rp4.png" border="0" /></center>

假定现在我们是“上帝”，“上帝”是知道总体分布的。假设总体是在0~9之间均匀分布的整型随机数，那么均值就是4.5，方差为8.25。接着我们回归凡人。现在我们不知道这个总体是怎样的分布；只知道，这个总体会产生0~9的某个整数。于是，我们利用中心极限定理，去计算出总体的均值和方差。现在，我们从总体里抽取n个数，n=40，计算样本均值 $\bar{x}$ 。这样就得到了一次抽样的结果。中心极限定理关注的是，样本均值i的均值和方差。那么，就需要多次重复上述采样的过程。

假设我们重复了1万次，这样就得到了1万次采样，每次采样40个样本的数据集。
<center><img src="https://s1.ax1x.com/2020/04/21/JG9XAf.png" alt="JG9XAf.png" border="0" /></center>

由于结果有随机性而且数据量非常大，我们尝试用Python进行仿真。这段代码中包含了两层循环。其中外层是1万次的采样循环，内层是每次采样获得40个样本的循环。每次获得40个样本后，我们需要计算这40个样本的均值。打印出来后，就得到了1万个均值。经过计算这1万个均值的均值和方差，得到均值为4.5033，方差为0.2058。最终，利用中心极限定理，我们可以对总体进行估计，得到总体的均值为4.5033，总体的方差为0.2058×40=8.2320。

# 均值假设检验

<center><img src="https://s1.ax1x.com/2020/04/21/JGCV4U.png" alt="JGCV4U.png" border="0" /></center>

计算完统计量是就需要去作出精准的决策了。例如，前面双倍工资加班的例子，就需要根据计算的统计量结果，去决策是否执行这个政策，以及执行风险有多大。根据统计量做决策就需要用到均值假设检验的相关方法了。

均值假设检验的目的在于，验证抽样得到的均值是否显著。显著的意义是，结果是真实客观的规律，并非偶然得到。那么假设检验的流程是，先对均值u的值提出一个假设，然后利用样本信息去检验这个假设是否成立。检验的方法是确定检验统计量，并计算数值，根据数值大小查表得到显著性p。通常显著性p<0.05为显著性。

当总体的标准差σ已知，且样本量n较大，则采用Z统计量，计算公式为
<center><img src="https://s1.ax1x.com/2020/04/21/JGCdKA.png" alt="111" border="0"></center>

当总体标准差未知，可以用样本标准差 s 代替，公式改写为
<center><img src="https://s1.ax1x.com/2020/04/21/JGCUvd.png" alt="112" border="0"></center>

## 例题

假设某机床厂加工一种零件，根据经验知道，该厂加工零件的椭圆度服从正态分布，起总体均值为0.081mm，今另换一种新机床进行加工，取200个零件进行检验，得到椭圆度均值为0.076mm，样本标准差为0.025mm，问新机床加工零件的椭圆度总体均值与以前有无显著差别？

在这个例子中，发现抽样得到的均值比总体均值小，问题的本质是在问，这个减小是偶然得到的，还是真实存在的，解题思路如图所示。

<center><img src="https://s1.ax1x.com/2020/04/21/JGCxVx.png" alt="JGCxVx.png" border="0" /></center>

根据定义，统计量的值为-2.83。我们用p表示显著性水平，通常取p<0.05为显著。当显著性为0.05时查询Z统计的表，可得到临界值为士1.96。我们发现此处的统计量绝对值为2.83，比1.96要大。Z的绝对值越大，对应p值越小，因此p<0.05，二者有显著相关，并非是偶然得到。此处关于假设检验的更多细节，我们不再展开。你需要建立的核心意识是，可以通过计算Z统计量，并通过查表得到显著性p值。根据p值就可以判断结果是偶然得到的还是真实存在的。

# AB实验

到这里，与机器学习强相关的统计学知识就已经准备妥当了。接下来看这些知识到底会在机器学习的哪个环节产生作用。

来看一个完整的机器学习项目。我们先粗略拆分一个机器学习项目为定义需求、建立模型、测试模型，即为什么做模型、怎么做的模型、以及如何测试模型效果这三个部分。统计学知识，更多是在“如何测试模型效果”这个环节中生效。也就是我们常说的开展AB实验的环节。

例如，你在今日头条工作，并开发了一个推荐系统。然后你需要验证这个推荐系统会使用户阅读文章的总数有所提高。那么你需要把用户拆分为无差别的两组。一组不施测推荐系统，另一组施测推荐系统。并观察两组用户阅读量的变化情况。接着你可能发现施测推荐系统的用户阅读量比另一组高，这样得到“推荐系统有效”的结论，那么这个结论就会被人质疑是否是偶然间得到的。为了让结果更有说服力，就需要用均值假设检验的知识来分析结果。你得到了抽样的结果，需要通过中心极限定理估计未知总体的统计量，然后根据假设检验的方法计算结果的显著性。如果显著，那么你的结果就是置信的、可靠的。最后，你就可以申请让你的模型从灰度测试到全量上线，创造更大范围的商业价值啦。这就是这些知识在机器学习中的作用。

<center><img src="https://s1.ax1x.com/2020/04/21/JGPrLR.png" alt="JGPrLR.png" border="0" /></center>


















